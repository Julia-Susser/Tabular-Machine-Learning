{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split,StratifiedKFold # Model evaluation\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, OneHotEncoder, StandardScaler # Preprocessing\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet,  LassoLarsIC, RANSACRegressor, SGDRegressor, HuberRegressor, BayesianRidge # Linear models\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor  # Ensemble methods\n",
    "from xgboost import XGBRegressor, plot_importance # XGBoost\n",
    "from sklearn.svm import SVR, SVC, LinearSVC  # Support Vector Regression\n",
    "from sklearn.tree import DecisionTreeRegressor # Decision Tree Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline # Streaming pipelines\n",
    "from sklearn.decomposition import KernelPCA, PCA # Dimensionality reduction\n",
    "from sklearn.feature_selection import SelectFromModel # Dimensionality reduction\n",
    "from sklearn.model_selection import learning_curve, validation_curve, GridSearchCV # Model evaluation\n",
    "from sklearn.base import clone, BaseEstimator, TransformerMixin, RegressorMixin # Clone estimator\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import explained_variance_score, roc_auc_score, median_absolute_error, r2_score, mean_squared_error #To evaluate our model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split \n",
    "from scipy.stats import norm, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spearman_corr:\n",
    "    def __init__(self,train,test,features):\n",
    "        self.features = features\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.categorical_cols = self.test.select_dtypes(\"object\").columns\n",
    "        self.numerical_cols = self.test.select_dtypes(exclude=\"object\").columns\n",
    "    def make_key(self):\n",
    "        self.key = pd.DataFrame(columns=[\"index\"], index=pd.MultiIndex.from_tuples([], names=['variable','value']))\n",
    "\n",
    "        for x in self.categorical_cols:\n",
    "            kf = self.train.groupby(x)[\"target\"].mean().to_frame().sort_values(\"target\")\n",
    "            kf = kf.reset_index().reset_index().drop(columns=[\"target\"])\n",
    "            kf[\"variable\"] = x\n",
    "            kf.index = kf.index + 1\n",
    "            self.key = pd.concat([self.key, kf.rename(columns={x:\"value\"}).set_index([\"variable\",\"value\"])])\n",
    "\n",
    "    def encode(self):\n",
    "        reshape_df = pd.melt(self.features, id_vars=\"id\", value_vars=self.categorical_cols).merge(self.key, on=[\"variable\",\"value\"])\n",
    "        qualDf= reshape_df.pivot(index='id', columns='variable')[\"index\"]\n",
    "        self.features = qualDf.merge(self.features[self.numerical_cols], on=[\"id\"])\n",
    "        \n",
    "  \n",
    "        self.new_train = self.features[:len(train)]\n",
    "        self.new_test = self.features[len(train):]\n",
    "    def get_key(self):\n",
    "        return self.key\n",
    "    def get_train(self):\n",
    "        return self.new_train\n",
    "    def get_test(self):\n",
    "        return self.new_test\n",
    "    def get_features(self):\n",
    "        return self.features\n",
    "    def get_y(self):\n",
    "        return self.train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "testID = test.id\n",
    "categorical_cols = train.select_dtypes(\"object\").columns\n",
    "y = train.target\n",
    "features = pd.concat([train.drop([\"target\"],axis=1)  ,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "def skew(features):\n",
    "    from scipy.stats import norm, skew\n",
    "    numeric_feats = features.dtypes[features.dtypes != \"object\"].index\n",
    "\n",
    "    # Check the skew of all numerical features\n",
    "    skewed_feats = features[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "    skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "\n",
    "\n",
    "    skewness = skewness[abs(skewness) > 0.75]\n",
    "    print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "    from scipy.special import boxcox1p\n",
    "    skewed_features = skewness.index\n",
    "    lam = 0.15\n",
    "    for feat in skewed_features:\n",
    "        features[feat] = boxcox1p(features[feat], lam)\n",
    "    return features\n",
    "\n",
    "if skew:\n",
    "    features = skew(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = True\n",
    "label_encoder = False\n",
    "overfit = False\n",
    "spearman = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for x in categorical_cols:\n",
    "        print(\"%s %s\" % (x, len(features[x].value_counts())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "if spearman:\n",
    "    spearman = spearman_corr(train,test,features)\n",
    "    spearman.make_key()\n",
    "    spearman.encode()\n",
    "    features = spearman.get_features()\n",
    "    features[features.select_dtypes(\"object\").columns] = features.select_dtypes(\"object\").fillna(0).astype(\"int\")\n",
    "    \n",
    "\n",
    "    \n",
    "if label_encoder:\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    cols = [\"cat10\",\"cat5\",\"cat8\",\"cat7\"]\n",
    "    for col in cols:\n",
    "        features[col] = le.fit_transform(features[col])\n",
    "        \n",
    "if one_hot:\n",
    "    features = pd.get_dummies(features)\n",
    "    if overfit:\n",
    "        x = features == 0\n",
    "        x = (x.sum()/len(features)>.99).to_frame()\n",
    "        drop_cols = x[x.iloc[:,0]].index\n",
    "        features = features.drop(drop_cols,axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop([\"id\"],axis=1)\n",
    "train = features[:len(y)]\n",
    "test = features[len(y):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression works like linear regression but shifts the line forward depending on where the switch is until it maximizes likelihood\n",
    "\n",
    "pipelines = {\n",
    "    \"logistic_regression\": Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ]),\n",
    "     \n",
    "    \n",
    "    \"xgb\": Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('classifier', XGBRegressor(objective ='reg:linear', \n",
    "                  n_estimators = 10, seed = 123)),\n",
    "    ]),\n",
    "    \n",
    "    \"xgb2\": xgb.XGBClassifier(n_estimators=5,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.5,\n",
    "    seed=123)\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'metric': 'auc', 'reg_alpha': 6.010538011450937, 'reg_lambda': 0.031702113663443346, 'colsample_bytree': 0.27,\n",
    "   'subsample': 0.6, 'learning_rate': 0.05, 'max_depth': 100, 'num_leaves': 100, 'min_child_samples': 216,\n",
    "   'cat_smooth': 87, 'random_state': 48,'n_estimators': 20000}\n",
    "clf = LGBMClassifier(**params) \n",
    "clf.fit(train,y)\n",
    "roc_auc_score(y,clf.predict(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'metric': 'auc', 'reg_alpha': 6.010538011450937, 'reg_lambda': 0.031702113663443346, 'colsample_bytree': 0.27,\n",
    "   'subsample': 0.6, 'learning_rate': 0.05, 'max_depth': 100, 'num_leaves': 100, 'min_child_samples': 216,\n",
    "   'cat_smooth': 87, 'random_state': 48,'n_estimators': 20000}\n",
    "preds = np.zeros(test.shape[0])        \n",
    "kf = StratifiedKFold(n_splits=5,random_state=48,shuffle=True) #As we can see the data is unbalanced that's why I'll use StratifiedKFold to split data: Don't want all zeros in a split                 \n",
    "auc=[]   # list contains AUC for each fold  \n",
    "n=0   \n",
    "for train_idx, test_idx in kf.split(train,y):\n",
    "    X_train,X_val=train.iloc[train_idx],train.iloc[test_idx]\n",
    "    y_train,y_val=y.iloc[train_idx],y.iloc[test_idx]\n",
    "    model = LGBMClassifier(**params) \n",
    "    model.fit(X_train,y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=100,verbose=False) \n",
    "    preds+=model.predict_proba(test)[:, 1]/kf.n_splits \n",
    "    auc.append(roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])) \n",
    "    print(n+1,auc[n])                                                                                       \n",
    "    n+=1    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22379294, 0.24854622, 0.21935728, ..., 0.27486289, 0.23127444,\n",
       "       0.22653514])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"id\":testID,\"target\":preds})\n",
    "#sub.to_csv(\"../output/LGBM_labelEncoded_sub2.csv.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.115566\n",
       "1         0.447129\n",
       "2         0.010611\n",
       "3         0.239745\n",
       "4         0.101847\n",
       "            ...   \n",
       "199995    0.896518\n",
       "199996    0.049339\n",
       "199997    0.701568\n",
       "199998    0.115219\n",
       "199999    0.526594\n",
       "Name: target, Length: 200000, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = pd.read_csv(\"../output/LGB_sub.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.223793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.248546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.219357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.221202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.228333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>499983</td>\n",
       "      <td>0.258002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>499984</td>\n",
       "      <td>0.219299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>499987</td>\n",
       "      <td>0.274863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>499994</td>\n",
       "      <td>0.231274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>499998</td>\n",
       "      <td>0.226535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    target\n",
       "0            5  0.223793\n",
       "1            6  0.248546\n",
       "2            8  0.219357\n",
       "3            9  0.221202\n",
       "4           11  0.228333\n",
       "...        ...       ...\n",
       "199995  499983  0.258002\n",
       "199996  499984  0.219299\n",
       "199997  499987  0.274863\n",
       "199998  499994  0.231274\n",
       "199999  499998  0.226535\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
