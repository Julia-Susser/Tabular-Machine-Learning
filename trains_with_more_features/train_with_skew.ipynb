{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split,StratifiedKFold # Model evaluation\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, OneHotEncoder, StandardScaler # Preprocessing\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet,  LassoLarsIC, RANSACRegressor, SGDRegressor, HuberRegressor, BayesianRidge # Linear models\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor  # Ensemble methods\n",
    "from xgboost import XGBRegressor, plot_importance # XGBoost\n",
    "from sklearn.svm import SVR, SVC, LinearSVC  # Support Vector Regression\n",
    "from sklearn.tree import DecisionTreeRegressor # Decision Tree Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline # Streaming pipelines\n",
    "from sklearn.decomposition import KernelPCA, PCA # Dimensionality reduction\n",
    "from sklearn.feature_selection import SelectFromModel # Dimensionality reduction\n",
    "from sklearn.model_selection import learning_curve, validation_curve, GridSearchCV # Model evaluation\n",
    "from sklearn.base import clone, BaseEstimator, TransformerMixin, RegressorMixin # Clone estimator\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import explained_variance_score, roc_auc_score, median_absolute_error, r2_score, mean_squared_error #To evaluate our model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "testID = test.id\n",
    "categorical_cols = train.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.target\n",
    "train = train.drop([\"target\"],axis=1)\n",
    "features = pd.concat([train,test])\n",
    "features = features.drop([\"id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm, skew\n",
    "numeric_feats = features.dtypes[features.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = features[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "\n",
    "\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    features[feat] = boxcox1p(features[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = False\n",
    "label_encoder = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if one_hot:\n",
    "    features = pd.get_dummies(features)\n",
    "    \n",
    "    \n",
    "    \n",
    "if label_encoder:\n",
    "    train = pd.read_csv(\"../input/train.csv\")\n",
    "    test = pd.read_csv(\"../input/test.csv\")\n",
    "    testID = test.id\n",
    "\n",
    "\n",
    "    all_df = pd.concat([train , test]).reset_index(drop = True)\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        all_df[col] = le.fit_transform(all_df[col])\n",
    "\n",
    "    train = all_df[:train.shape[0]]\n",
    "    test = all_df[train.shape[0]:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features == 0\n",
    "x = (x.sum()/len(features)>.99).to_frame()\n",
    "drop_cols = x[x.iloc[:,0]].index\n",
    "features = features.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = features[:len(y)]\n",
    "test = features[len(y):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression works like linear regression but shifts the line forward depending on where the switch is until it maximizes likelihood\n",
    "\n",
    "pipelines = {\n",
    "    \"logistic_regression\": Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ]),\n",
    "     \n",
    "    \n",
    "    \"xgb\": Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('classifier', XGBRegressor(objective ='reg:linear', \n",
    "                  n_estimators = 10, seed = 123)),\n",
    "    ]),\n",
    "    \n",
    "    \"xgb2\": xgb.XGBClassifier(n_estimators=5,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.5,\n",
    "    seed=123)\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipelines[\"logistic_regression\"]\n",
    "clf.fit(train,y)\n",
    "clf.score(train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "seed = 5\n",
    "n_folds =5\n",
    "scoring='auc'\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "np.sqrt(-cross_val_score(clf, train, y, cv= kfold,\n",
    "                                 scoring=scoring, n_jobs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8885469802275362\n",
      "0.8905813405034633\n",
      "0.8880096690111776\n",
      "0.8899067940597765\n",
      "0.8903925300056434\n"
     ]
    }
   ],
   "source": [
    "params={'metric': 'auc', 'reg_alpha': 6.010538011450937, 'reg_lambda': 0.031702113663443346, 'colsample_bytree': 0.27,\n",
    "   'subsample': 0.6, 'learning_rate': 0.05, 'max_depth': 100, 'num_leaves': 100, 'min_child_samples': 216,\n",
    "   'cat_smooth': 87, 'random_state': 48,'n_estimators': 100}\n",
    "preds = np.zeros(test.shape[0])        \n",
    "kf = StratifiedKFold(n_splits=5,random_state=48,shuffle=True) #As we can see the data is unbalanced that's why I'll use StratifiedKFold to split data: Don't want all zeros in a split                 \n",
    "auc=[]   # list contains AUC for each fold  \n",
    "n=0   \n",
    "for trainVals, testVals in kf.split(train,y):\n",
    "    Xtrain,Xval=train.iloc[trainVals],train.iloc[testVals]\n",
    "    ytrain,yval=y.iloc[trainVals],y.iloc[testVals]\n",
    "    model = LGBMClassifier(**params) \n",
    "    model.fit(Xtrain,ytrain, eval_set=[(Xval,yval)], early_stopping_rounds=100,verbose=False)\n",
    "    score = roc_auc_score(yval, model.predict_proba(Xval)[:, 1])\n",
    "    print(score)\n",
    "    preds += model.predict_proba(test)[:, 1]/kf.n_splits \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"id\":testID,\"target\":preds})\n",
    "sub.to_csv(\"../output/LGB_sub2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.115566\n",
       "1         0.447129\n",
       "2         0.010611\n",
       "3         0.239745\n",
       "4         0.101847\n",
       "            ...   \n",
       "199995    0.896518\n",
       "199996    0.049339\n",
       "199997    0.701568\n",
       "199998    0.115219\n",
       "199999    0.526594\n",
       "Name: target, Length: 200000, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = pd.read_csv(\"../output/LGB_sub.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
