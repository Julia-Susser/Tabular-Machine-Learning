{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split,StratifiedKFold # Model evaluation\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, OneHotEncoder, StandardScaler # Preprocessing\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet,  LassoLarsIC, RANSACRegressor, SGDRegressor, HuberRegressor, BayesianRidge # Linear models\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor, ExtraTreesRegressor  # Ensemble methods\n",
    "from xgboost import XGBRegressor, plot_importance # XGBoost\n",
    "from sklearn.svm import SVR, SVC, LinearSVC  # Support Vector Regression\n",
    "from sklearn.tree import DecisionTreeRegressor # Decision Tree Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline, make_pipeline # Streaming pipelines\n",
    "from sklearn.decomposition import KernelPCA, PCA # Dimensionality reduction\n",
    "from sklearn.feature_selection import SelectFromModel # Dimensionality reduction\n",
    "from sklearn.model_selection import learning_curve, validation_curve, GridSearchCV # Model evaluation\n",
    "from sklearn.base import clone, BaseEstimator, TransformerMixin, RegressorMixin # Clone estimator\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import explained_variance_score, roc_auc_score, median_absolute_error, r2_score, mean_squared_error #To evaluate our model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, fbeta_score #To evaluate our model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "testID = test.id\n",
    "categorical_cols = train.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.target\n",
    "train = train.drop([\"target\"],axis=1)\n",
    "features = pd.concat([train,test])\n",
    "features = features.drop([\"id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm, skew\n",
    "numeric_feats = features.dtypes[features.dtypes != \"object\"].index\n",
    "\n",
    "# Check the skew of all numerical features\n",
    "skewed_feats = features[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "\n",
    "\n",
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    features[feat] = boxcox1p(features[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = True\n",
    "label_encoder = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if one_hot:\n",
    "    features = pd.get_dummies(features)\n",
    "    \n",
    "    \n",
    "    \n",
    "if label_encoder:\n",
    "    train = pd.read_csv(\"../input/train.csv\")\n",
    "    test = pd.read_csv(\"../input/test.csv\")\n",
    "    testID = test.id\n",
    "\n",
    "\n",
    "    all_df = pd.concat([train , test]).reset_index(drop = True)\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        all_df[col] = le.fit_transform(all_df[col])\n",
    "\n",
    "    train = all_df[:train.shape[0]]\n",
    "    test = all_df[train.shape[0]:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features == 0\n",
    "x = (x.sum()/len(features)>.99).to_frame()\n",
    "drop_cols = x[x.iloc[:,0]].index\n",
    "features = features.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = features[:len(y)]\n",
    "test = features[len(y):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression works like linear regression but shifts the line forward depending on where the switch is until it maximizes likelihood\n",
    "\n",
    "pipelines = {\n",
    "    \"logistic_regression\": Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression()),\n",
    "    ]),\n",
    "     \n",
    "    \n",
    "    \"xgb\": Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('classifier', XGBRegressor(objective ='reg:linear', \n",
    "                  n_estimators = 10, seed = 123)),\n",
    "    ]),\n",
    "    \n",
    "    \"xgb2\": xgb.XGBClassifier(n_estimators=5,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.5,\n",
    "    seed=123)\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = pipelines[\"logistic_regression\"]\n",
    "clf.fit(train,y)\n",
    "clf.score(train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:08:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "seed = 5\n",
    "n_folds =5\n",
    "scoring='auc'\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "np.sqrt(-cross_val_score(clf, train, y, cv= kfold,\n",
    "                                 scoring=scoring, n_jobs=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.844622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.854938\n",
      "[3]\tvalid_0's auc: 0.851165\n",
      "[4]\tvalid_0's auc: 0.864183\n",
      "[5]\tvalid_0's auc: 0.869804\n",
      "[6]\tvalid_0's auc: 0.870141\n",
      "[7]\tvalid_0's auc: 0.871167\n",
      "[8]\tvalid_0's auc: 0.871555\n",
      "[9]\tvalid_0's auc: 0.872293\n",
      "[10]\tvalid_0's auc: 0.875212\n",
      "[11]\tvalid_0's auc: 0.876374\n",
      "[12]\tvalid_0's auc: 0.877178\n",
      "[13]\tvalid_0's auc: 0.877234\n",
      "[14]\tvalid_0's auc: 0.877757\n",
      "[15]\tvalid_0's auc: 0.878176\n",
      "[16]\tvalid_0's auc: 0.878569\n",
      "[17]\tvalid_0's auc: 0.878475\n",
      "[18]\tvalid_0's auc: 0.878429\n",
      "[19]\tvalid_0's auc: 0.878268\n",
      "[20]\tvalid_0's auc: 0.878822\n",
      "[21]\tvalid_0's auc: 0.879371\n",
      "[22]\tvalid_0's auc: 0.879681\n",
      "[23]\tvalid_0's auc: 0.879984\n",
      "[24]\tvalid_0's auc: 0.879871\n",
      "[25]\tvalid_0's auc: 0.880196\n",
      "[26]\tvalid_0's auc: 0.880641\n",
      "[27]\tvalid_0's auc: 0.880802\n",
      "[28]\tvalid_0's auc: 0.880971\n",
      "[29]\tvalid_0's auc: 0.881172\n",
      "[30]\tvalid_0's auc: 0.881239\n",
      "[31]\tvalid_0's auc: 0.881453\n",
      "[32]\tvalid_0's auc: 0.881777\n",
      "[33]\tvalid_0's auc: 0.881865\n",
      "[34]\tvalid_0's auc: 0.88193\n",
      "[35]\tvalid_0's auc: 0.882058\n",
      "[36]\tvalid_0's auc: 0.882203\n",
      "[37]\tvalid_0's auc: 0.882295\n",
      "[38]\tvalid_0's auc: 0.882346\n",
      "[39]\tvalid_0's auc: 0.882409\n",
      "[40]\tvalid_0's auc: 0.882645\n",
      "[41]\tvalid_0's auc: 0.882692\n",
      "[42]\tvalid_0's auc: 0.882767\n",
      "[43]\tvalid_0's auc: 0.88292\n",
      "[44]\tvalid_0's auc: 0.882987\n",
      "[45]\tvalid_0's auc: 0.88319\n",
      "[46]\tvalid_0's auc: 0.883275\n",
      "[47]\tvalid_0's auc: 0.883552\n",
      "[48]\tvalid_0's auc: 0.883699\n",
      "[49]\tvalid_0's auc: 0.883777\n",
      "[50]\tvalid_0's auc: 0.883848\n",
      "[51]\tvalid_0's auc: 0.884118\n",
      "[52]\tvalid_0's auc: 0.884216\n",
      "[53]\tvalid_0's auc: 0.884344\n",
      "[54]\tvalid_0's auc: 0.884497\n",
      "[55]\tvalid_0's auc: 0.884618\n",
      "[56]\tvalid_0's auc: 0.8848\n",
      "[57]\tvalid_0's auc: 0.884923\n",
      "[58]\tvalid_0's auc: 0.885185\n",
      "[59]\tvalid_0's auc: 0.88523\n",
      "[60]\tvalid_0's auc: 0.885272\n",
      "[61]\tvalid_0's auc: 0.885343\n",
      "[62]\tvalid_0's auc: 0.885436\n",
      "[63]\tvalid_0's auc: 0.885527\n",
      "[64]\tvalid_0's auc: 0.88563\n",
      "[65]\tvalid_0's auc: 0.885743\n",
      "[66]\tvalid_0's auc: 0.885918\n",
      "[67]\tvalid_0's auc: 0.886032\n",
      "[68]\tvalid_0's auc: 0.886185\n",
      "[69]\tvalid_0's auc: 0.88631\n",
      "[70]\tvalid_0's auc: 0.886407\n",
      "[71]\tvalid_0's auc: 0.886499\n",
      "[72]\tvalid_0's auc: 0.886645\n",
      "[73]\tvalid_0's auc: 0.886777\n",
      "[74]\tvalid_0's auc: 0.886814\n",
      "[75]\tvalid_0's auc: 0.88687\n",
      "[76]\tvalid_0's auc: 0.886963\n",
      "[77]\tvalid_0's auc: 0.887056\n",
      "[78]\tvalid_0's auc: 0.887133\n",
      "[79]\tvalid_0's auc: 0.887205\n",
      "[80]\tvalid_0's auc: 0.887307\n",
      "[81]\tvalid_0's auc: 0.887344\n",
      "[82]\tvalid_0's auc: 0.887428\n",
      "[83]\tvalid_0's auc: 0.887529\n",
      "[84]\tvalid_0's auc: 0.887572\n",
      "[85]\tvalid_0's auc: 0.887647\n",
      "[86]\tvalid_0's auc: 0.887724\n",
      "[87]\tvalid_0's auc: 0.887786\n",
      "[88]\tvalid_0's auc: 0.887834\n",
      "[89]\tvalid_0's auc: 0.887937\n",
      "[90]\tvalid_0's auc: 0.887998\n",
      "[91]\tvalid_0's auc: 0.888063\n",
      "[92]\tvalid_0's auc: 0.888128\n",
      "[93]\tvalid_0's auc: 0.888165\n",
      "[94]\tvalid_0's auc: 0.888217\n",
      "[95]\tvalid_0's auc: 0.888248\n",
      "[96]\tvalid_0's auc: 0.888336\n",
      "[97]\tvalid_0's auc: 0.888376\n",
      "[98]\tvalid_0's auc: 0.888429\n",
      "[99]\tvalid_0's auc: 0.888486\n",
      "[100]\tvalid_0's auc: 0.888547\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.888547\n",
      "0.8885469802275362\n",
      "[1]\tvalid_0's auc: 0.846277\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.857287\n",
      "[3]\tvalid_0's auc: 0.854806\n",
      "[4]\tvalid_0's auc: 0.866966\n",
      "[5]\tvalid_0's auc: 0.872697\n",
      "[6]\tvalid_0's auc: 0.873158\n",
      "[7]\tvalid_0's auc: 0.874141\n",
      "[8]\tvalid_0's auc: 0.874533\n",
      "[9]\tvalid_0's auc: 0.875289\n",
      "[10]\tvalid_0's auc: 0.87808\n",
      "[11]\tvalid_0's auc: 0.878903\n",
      "[12]\tvalid_0's auc: 0.879941\n",
      "[13]\tvalid_0's auc: 0.880137\n",
      "[14]\tvalid_0's auc: 0.880574\n",
      "[15]\tvalid_0's auc: 0.880968\n",
      "[16]\tvalid_0's auc: 0.88144\n",
      "[17]\tvalid_0's auc: 0.881364\n",
      "[18]\tvalid_0's auc: 0.881432\n",
      "[19]\tvalid_0's auc: 0.881349\n",
      "[20]\tvalid_0's auc: 0.881789\n",
      "[21]\tvalid_0's auc: 0.882263\n",
      "[22]\tvalid_0's auc: 0.882418\n",
      "[23]\tvalid_0's auc: 0.882711\n",
      "[24]\tvalid_0's auc: 0.882676\n",
      "[25]\tvalid_0's auc: 0.883004\n",
      "[26]\tvalid_0's auc: 0.88339\n",
      "[27]\tvalid_0's auc: 0.883582\n",
      "[28]\tvalid_0's auc: 0.883679\n",
      "[29]\tvalid_0's auc: 0.883804\n",
      "[30]\tvalid_0's auc: 0.883895\n",
      "[31]\tvalid_0's auc: 0.884155\n",
      "[32]\tvalid_0's auc: 0.884427\n",
      "[33]\tvalid_0's auc: 0.884524\n",
      "[34]\tvalid_0's auc: 0.884594\n",
      "[35]\tvalid_0's auc: 0.884613\n",
      "[36]\tvalid_0's auc: 0.884751\n",
      "[37]\tvalid_0's auc: 0.884809\n",
      "[38]\tvalid_0's auc: 0.884853\n",
      "[39]\tvalid_0's auc: 0.884874\n",
      "[40]\tvalid_0's auc: 0.885078\n",
      "[41]\tvalid_0's auc: 0.885188\n",
      "[42]\tvalid_0's auc: 0.885276\n",
      "[43]\tvalid_0's auc: 0.885446\n",
      "[44]\tvalid_0's auc: 0.88551\n",
      "[45]\tvalid_0's auc: 0.885694\n",
      "[46]\tvalid_0's auc: 0.885779\n",
      "[47]\tvalid_0's auc: 0.886052\n",
      "[48]\tvalid_0's auc: 0.886223\n",
      "[49]\tvalid_0's auc: 0.886232\n",
      "[50]\tvalid_0's auc: 0.88626\n",
      "[51]\tvalid_0's auc: 0.88653\n",
      "[52]\tvalid_0's auc: 0.886619\n",
      "[53]\tvalid_0's auc: 0.886719\n",
      "[54]\tvalid_0's auc: 0.886862\n",
      "[55]\tvalid_0's auc: 0.886972\n",
      "[56]\tvalid_0's auc: 0.88716\n",
      "[57]\tvalid_0's auc: 0.887311\n",
      "[58]\tvalid_0's auc: 0.887519\n",
      "[59]\tvalid_0's auc: 0.88757\n",
      "[60]\tvalid_0's auc: 0.887605\n",
      "[61]\tvalid_0's auc: 0.887665\n",
      "[62]\tvalid_0's auc: 0.887773\n",
      "[63]\tvalid_0's auc: 0.887874\n",
      "[64]\tvalid_0's auc: 0.887972\n",
      "[65]\tvalid_0's auc: 0.888066\n",
      "[66]\tvalid_0's auc: 0.88823\n",
      "[67]\tvalid_0's auc: 0.888345\n",
      "[68]\tvalid_0's auc: 0.8885\n",
      "[69]\tvalid_0's auc: 0.888607\n",
      "[70]\tvalid_0's auc: 0.888704\n",
      "[71]\tvalid_0's auc: 0.888785\n",
      "[72]\tvalid_0's auc: 0.88895\n",
      "[73]\tvalid_0's auc: 0.889112\n",
      "[74]\tvalid_0's auc: 0.889159\n",
      "[75]\tvalid_0's auc: 0.889224\n",
      "[76]\tvalid_0's auc: 0.889291\n",
      "[77]\tvalid_0's auc: 0.889343\n",
      "[78]\tvalid_0's auc: 0.889423\n",
      "[79]\tvalid_0's auc: 0.889448\n",
      "[80]\tvalid_0's auc: 0.889565\n",
      "[81]\tvalid_0's auc: 0.889597\n",
      "[82]\tvalid_0's auc: 0.889653\n",
      "[83]\tvalid_0's auc: 0.889735\n",
      "[84]\tvalid_0's auc: 0.88976\n",
      "[85]\tvalid_0's auc: 0.889804\n",
      "[86]\tvalid_0's auc: 0.88985\n",
      "[87]\tvalid_0's auc: 0.889904\n",
      "[88]\tvalid_0's auc: 0.889937\n",
      "[89]\tvalid_0's auc: 0.890038\n",
      "[90]\tvalid_0's auc: 0.890068\n",
      "[91]\tvalid_0's auc: 0.890137\n",
      "[92]\tvalid_0's auc: 0.890178\n",
      "[93]\tvalid_0's auc: 0.890196\n",
      "[94]\tvalid_0's auc: 0.89025\n",
      "[95]\tvalid_0's auc: 0.890288\n",
      "[96]\tvalid_0's auc: 0.890376\n",
      "[97]\tvalid_0's auc: 0.890422\n",
      "[98]\tvalid_0's auc: 0.890483\n",
      "[99]\tvalid_0's auc: 0.890522\n",
      "[100]\tvalid_0's auc: 0.890581\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.890581\n",
      "0.8905813405034633\n",
      "[1]\tvalid_0's auc: 0.843544\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.853684\n",
      "[3]\tvalid_0's auc: 0.850534\n",
      "[4]\tvalid_0's auc: 0.863528\n",
      "[5]\tvalid_0's auc: 0.868896\n",
      "[6]\tvalid_0's auc: 0.869204\n",
      "[7]\tvalid_0's auc: 0.8707\n",
      "[8]\tvalid_0's auc: 0.87096\n",
      "[9]\tvalid_0's auc: 0.871474\n",
      "[10]\tvalid_0's auc: 0.874523\n",
      "[11]\tvalid_0's auc: 0.875617\n",
      "[12]\tvalid_0's auc: 0.876419\n",
      "[13]\tvalid_0's auc: 0.876592\n",
      "[14]\tvalid_0's auc: 0.877051\n",
      "[15]\tvalid_0's auc: 0.877558\n",
      "[16]\tvalid_0's auc: 0.877808\n",
      "[17]\tvalid_0's auc: 0.877801\n",
      "[18]\tvalid_0's auc: 0.877821\n",
      "[19]\tvalid_0's auc: 0.877628\n",
      "[20]\tvalid_0's auc: 0.878153\n",
      "[21]\tvalid_0's auc: 0.878731\n",
      "[22]\tvalid_0's auc: 0.87896\n",
      "[23]\tvalid_0's auc: 0.879392\n",
      "[24]\tvalid_0's auc: 0.879436\n",
      "[25]\tvalid_0's auc: 0.87979\n",
      "[26]\tvalid_0's auc: 0.880245\n",
      "[27]\tvalid_0's auc: 0.880431\n",
      "[28]\tvalid_0's auc: 0.880543\n",
      "[29]\tvalid_0's auc: 0.880749\n",
      "[30]\tvalid_0's auc: 0.88088\n",
      "[31]\tvalid_0's auc: 0.881082\n",
      "[32]\tvalid_0's auc: 0.881405\n",
      "[33]\tvalid_0's auc: 0.881513\n",
      "[34]\tvalid_0's auc: 0.881541\n",
      "[35]\tvalid_0's auc: 0.881653\n",
      "[36]\tvalid_0's auc: 0.881772\n",
      "[37]\tvalid_0's auc: 0.881825\n",
      "[38]\tvalid_0's auc: 0.881835\n",
      "[39]\tvalid_0's auc: 0.881864\n",
      "[40]\tvalid_0's auc: 0.882032\n",
      "[41]\tvalid_0's auc: 0.88217\n",
      "[42]\tvalid_0's auc: 0.882289\n",
      "[43]\tvalid_0's auc: 0.882519\n",
      "[44]\tvalid_0's auc: 0.882585\n",
      "[45]\tvalid_0's auc: 0.882793\n",
      "[46]\tvalid_0's auc: 0.882886\n",
      "[47]\tvalid_0's auc: 0.883149\n",
      "[48]\tvalid_0's auc: 0.883315\n",
      "[49]\tvalid_0's auc: 0.883377\n",
      "[50]\tvalid_0's auc: 0.883473\n",
      "[51]\tvalid_0's auc: 0.883694\n",
      "[52]\tvalid_0's auc: 0.883802\n",
      "[53]\tvalid_0's auc: 0.883945\n",
      "[54]\tvalid_0's auc: 0.88411\n",
      "[55]\tvalid_0's auc: 0.884214\n",
      "[56]\tvalid_0's auc: 0.884384\n",
      "[57]\tvalid_0's auc: 0.88455\n",
      "[58]\tvalid_0's auc: 0.884787\n",
      "[59]\tvalid_0's auc: 0.884842\n",
      "[60]\tvalid_0's auc: 0.884865\n",
      "[61]\tvalid_0's auc: 0.884936\n",
      "[62]\tvalid_0's auc: 0.885044\n",
      "[63]\tvalid_0's auc: 0.885148\n",
      "[64]\tvalid_0's auc: 0.885247\n",
      "[65]\tvalid_0's auc: 0.88537\n",
      "[66]\tvalid_0's auc: 0.885517\n",
      "[67]\tvalid_0's auc: 0.885634\n",
      "[68]\tvalid_0's auc: 0.885787\n",
      "[69]\tvalid_0's auc: 0.885921\n",
      "[70]\tvalid_0's auc: 0.886015\n",
      "[71]\tvalid_0's auc: 0.886095\n",
      "[72]\tvalid_0's auc: 0.886204\n",
      "[73]\tvalid_0's auc: 0.886315\n",
      "[74]\tvalid_0's auc: 0.886339\n",
      "[75]\tvalid_0's auc: 0.886412\n",
      "[76]\tvalid_0's auc: 0.886489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77]\tvalid_0's auc: 0.886581\n",
      "[78]\tvalid_0's auc: 0.886639\n",
      "[79]\tvalid_0's auc: 0.886665\n",
      "[80]\tvalid_0's auc: 0.88677\n",
      "[81]\tvalid_0's auc: 0.886823\n",
      "[82]\tvalid_0's auc: 0.886906\n",
      "[83]\tvalid_0's auc: 0.88702\n",
      "[84]\tvalid_0's auc: 0.887041\n",
      "[85]\tvalid_0's auc: 0.887092\n",
      "[86]\tvalid_0's auc: 0.887152\n",
      "[87]\tvalid_0's auc: 0.8872\n",
      "[88]\tvalid_0's auc: 0.887275\n",
      "[89]\tvalid_0's auc: 0.887394\n",
      "[90]\tvalid_0's auc: 0.887464\n",
      "[91]\tvalid_0's auc: 0.887514\n",
      "[92]\tvalid_0's auc: 0.887555\n",
      "[93]\tvalid_0's auc: 0.887594\n",
      "[94]\tvalid_0's auc: 0.887672\n",
      "[95]\tvalid_0's auc: 0.88771\n",
      "[96]\tvalid_0's auc: 0.887785\n",
      "[97]\tvalid_0's auc: 0.887836\n",
      "[98]\tvalid_0's auc: 0.887888\n",
      "[99]\tvalid_0's auc: 0.887943\n",
      "[100]\tvalid_0's auc: 0.88801\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.88801\n",
      "0.8880096690111776\n",
      "[1]\tvalid_0's auc: 0.846649\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.85768\n",
      "[3]\tvalid_0's auc: 0.854405\n",
      "[4]\tvalid_0's auc: 0.867036\n",
      "[5]\tvalid_0's auc: 0.871789\n",
      "[6]\tvalid_0's auc: 0.871946\n",
      "[7]\tvalid_0's auc: 0.873356\n",
      "[8]\tvalid_0's auc: 0.873712\n",
      "[9]\tvalid_0's auc: 0.874089\n",
      "[10]\tvalid_0's auc: 0.876849\n",
      "[11]\tvalid_0's auc: 0.877892\n",
      "[12]\tvalid_0's auc: 0.878914\n",
      "[13]\tvalid_0's auc: 0.879223\n",
      "[14]\tvalid_0's auc: 0.879688\n",
      "[15]\tvalid_0's auc: 0.880111\n",
      "[16]\tvalid_0's auc: 0.880461\n",
      "[17]\tvalid_0's auc: 0.88034\n",
      "[18]\tvalid_0's auc: 0.880266\n",
      "[19]\tvalid_0's auc: 0.88011\n",
      "[20]\tvalid_0's auc: 0.880642\n",
      "[21]\tvalid_0's auc: 0.881135\n",
      "[22]\tvalid_0's auc: 0.88141\n",
      "[23]\tvalid_0's auc: 0.881665\n",
      "[24]\tvalid_0's auc: 0.881529\n",
      "[25]\tvalid_0's auc: 0.881904\n",
      "[26]\tvalid_0's auc: 0.882388\n",
      "[27]\tvalid_0's auc: 0.8825\n",
      "[28]\tvalid_0's auc: 0.882552\n",
      "[29]\tvalid_0's auc: 0.882696\n",
      "[30]\tvalid_0's auc: 0.88283\n",
      "[31]\tvalid_0's auc: 0.883053\n",
      "[32]\tvalid_0's auc: 0.883305\n",
      "[33]\tvalid_0's auc: 0.883429\n",
      "[34]\tvalid_0's auc: 0.883497\n",
      "[35]\tvalid_0's auc: 0.883571\n",
      "[36]\tvalid_0's auc: 0.883733\n",
      "[37]\tvalid_0's auc: 0.883772\n",
      "[38]\tvalid_0's auc: 0.883775\n",
      "[39]\tvalid_0's auc: 0.88382\n",
      "[40]\tvalid_0's auc: 0.88405\n",
      "[41]\tvalid_0's auc: 0.884191\n",
      "[42]\tvalid_0's auc: 0.884272\n",
      "[43]\tvalid_0's auc: 0.884461\n",
      "[44]\tvalid_0's auc: 0.884514\n",
      "[45]\tvalid_0's auc: 0.884668\n",
      "[46]\tvalid_0's auc: 0.884764\n",
      "[47]\tvalid_0's auc: 0.884975\n",
      "[48]\tvalid_0's auc: 0.885163\n",
      "[49]\tvalid_0's auc: 0.885226\n",
      "[50]\tvalid_0's auc: 0.885275\n",
      "[51]\tvalid_0's auc: 0.885534\n",
      "[52]\tvalid_0's auc: 0.885657\n",
      "[53]\tvalid_0's auc: 0.885838\n",
      "[54]\tvalid_0's auc: 0.885981\n",
      "[55]\tvalid_0's auc: 0.886102\n",
      "[56]\tvalid_0's auc: 0.886287\n",
      "[57]\tvalid_0's auc: 0.886399\n",
      "[58]\tvalid_0's auc: 0.886639\n",
      "[59]\tvalid_0's auc: 0.886675\n",
      "[60]\tvalid_0's auc: 0.886732\n",
      "[61]\tvalid_0's auc: 0.886829\n",
      "[62]\tvalid_0's auc: 0.886926\n",
      "[63]\tvalid_0's auc: 0.887045\n",
      "[64]\tvalid_0's auc: 0.887135\n",
      "[65]\tvalid_0's auc: 0.887246\n",
      "[66]\tvalid_0's auc: 0.887378\n",
      "[67]\tvalid_0's auc: 0.887462\n",
      "[68]\tvalid_0's auc: 0.88762\n",
      "[69]\tvalid_0's auc: 0.887744\n",
      "[70]\tvalid_0's auc: 0.88789\n",
      "[71]\tvalid_0's auc: 0.887947\n",
      "[72]\tvalid_0's auc: 0.888071\n",
      "[73]\tvalid_0's auc: 0.888209\n",
      "[74]\tvalid_0's auc: 0.888234\n",
      "[75]\tvalid_0's auc: 0.88828\n",
      "[76]\tvalid_0's auc: 0.888364\n",
      "[77]\tvalid_0's auc: 0.888455\n",
      "[78]\tvalid_0's auc: 0.888527\n",
      "[79]\tvalid_0's auc: 0.888568\n",
      "[80]\tvalid_0's auc: 0.888704\n",
      "[81]\tvalid_0's auc: 0.888753\n",
      "[82]\tvalid_0's auc: 0.888841\n",
      "[83]\tvalid_0's auc: 0.888911\n",
      "[84]\tvalid_0's auc: 0.888957\n",
      "[85]\tvalid_0's auc: 0.889026\n",
      "[86]\tvalid_0's auc: 0.889086\n",
      "[87]\tvalid_0's auc: 0.88915\n",
      "[88]\tvalid_0's auc: 0.889214\n",
      "[89]\tvalid_0's auc: 0.889298\n",
      "[90]\tvalid_0's auc: 0.889359\n",
      "[91]\tvalid_0's auc: 0.889417\n",
      "[92]\tvalid_0's auc: 0.889468\n",
      "[93]\tvalid_0's auc: 0.889499\n",
      "[94]\tvalid_0's auc: 0.889578\n",
      "[95]\tvalid_0's auc: 0.889619\n",
      "[96]\tvalid_0's auc: 0.889698\n",
      "[97]\tvalid_0's auc: 0.889754\n",
      "[98]\tvalid_0's auc: 0.889801\n",
      "[99]\tvalid_0's auc: 0.889841\n",
      "[100]\tvalid_0's auc: 0.889907\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.889907\n",
      "0.8899067940597765\n",
      "[1]\tvalid_0's auc: 0.847751\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.856152\n",
      "[3]\tvalid_0's auc: 0.853202\n",
      "[4]\tvalid_0's auc: 0.866204\n",
      "[5]\tvalid_0's auc: 0.871284\n",
      "[6]\tvalid_0's auc: 0.871536\n",
      "[7]\tvalid_0's auc: 0.873065\n",
      "[8]\tvalid_0's auc: 0.873423\n",
      "[9]\tvalid_0's auc: 0.874108\n",
      "[10]\tvalid_0's auc: 0.877024\n",
      "[11]\tvalid_0's auc: 0.878217\n",
      "[12]\tvalid_0's auc: 0.879018\n",
      "[13]\tvalid_0's auc: 0.879182\n",
      "[14]\tvalid_0's auc: 0.87973\n",
      "[15]\tvalid_0's auc: 0.880192\n",
      "[16]\tvalid_0's auc: 0.880451\n",
      "[17]\tvalid_0's auc: 0.880441\n",
      "[18]\tvalid_0's auc: 0.880282\n",
      "[19]\tvalid_0's auc: 0.880089\n",
      "[20]\tvalid_0's auc: 0.880652\n",
      "[21]\tvalid_0's auc: 0.881149\n",
      "[22]\tvalid_0's auc: 0.881452\n",
      "[23]\tvalid_0's auc: 0.881813\n",
      "[24]\tvalid_0's auc: 0.881673\n",
      "[25]\tvalid_0's auc: 0.882027\n",
      "[26]\tvalid_0's auc: 0.882421\n",
      "[27]\tvalid_0's auc: 0.882627\n",
      "[28]\tvalid_0's auc: 0.882679\n",
      "[29]\tvalid_0's auc: 0.882873\n",
      "[30]\tvalid_0's auc: 0.882965\n",
      "[31]\tvalid_0's auc: 0.883132\n",
      "[32]\tvalid_0's auc: 0.883471\n",
      "[33]\tvalid_0's auc: 0.883575\n",
      "[34]\tvalid_0's auc: 0.883624\n",
      "[35]\tvalid_0's auc: 0.883715\n",
      "[36]\tvalid_0's auc: 0.883866\n",
      "[37]\tvalid_0's auc: 0.883951\n",
      "[38]\tvalid_0's auc: 0.883969\n",
      "[39]\tvalid_0's auc: 0.88407\n",
      "[40]\tvalid_0's auc: 0.884275\n",
      "[41]\tvalid_0's auc: 0.884341\n",
      "[42]\tvalid_0's auc: 0.884464\n",
      "[43]\tvalid_0's auc: 0.88465\n",
      "[44]\tvalid_0's auc: 0.88475\n",
      "[45]\tvalid_0's auc: 0.884994\n",
      "[46]\tvalid_0's auc: 0.885079\n",
      "[47]\tvalid_0's auc: 0.885371\n",
      "[48]\tvalid_0's auc: 0.885515\n",
      "[49]\tvalid_0's auc: 0.885609\n",
      "[50]\tvalid_0's auc: 0.885653\n",
      "[51]\tvalid_0's auc: 0.885919\n",
      "[52]\tvalid_0's auc: 0.886056\n",
      "[53]\tvalid_0's auc: 0.886258\n",
      "[54]\tvalid_0's auc: 0.886395\n",
      "[55]\tvalid_0's auc: 0.886479\n",
      "[56]\tvalid_0's auc: 0.886687\n",
      "[57]\tvalid_0's auc: 0.886849\n",
      "[58]\tvalid_0's auc: 0.887076\n",
      "[59]\tvalid_0's auc: 0.887152\n",
      "[60]\tvalid_0's auc: 0.887198\n",
      "[61]\tvalid_0's auc: 0.88728\n",
      "[62]\tvalid_0's auc: 0.887381\n",
      "[63]\tvalid_0's auc: 0.887479\n",
      "[64]\tvalid_0's auc: 0.887571\n",
      "[65]\tvalid_0's auc: 0.8877\n",
      "[66]\tvalid_0's auc: 0.887832\n",
      "[67]\tvalid_0's auc: 0.887954\n",
      "[68]\tvalid_0's auc: 0.888095\n",
      "[69]\tvalid_0's auc: 0.88822\n",
      "[70]\tvalid_0's auc: 0.888332\n",
      "[71]\tvalid_0's auc: 0.888406\n",
      "[72]\tvalid_0's auc: 0.888539\n",
      "[73]\tvalid_0's auc: 0.888659\n",
      "[74]\tvalid_0's auc: 0.888736\n",
      "[75]\tvalid_0's auc: 0.888778\n",
      "[76]\tvalid_0's auc: 0.888883\n",
      "[77]\tvalid_0's auc: 0.888953\n",
      "[78]\tvalid_0's auc: 0.889032\n",
      "[79]\tvalid_0's auc: 0.889085\n",
      "[80]\tvalid_0's auc: 0.889195\n",
      "[81]\tvalid_0's auc: 0.889256\n",
      "[82]\tvalid_0's auc: 0.88932\n",
      "[83]\tvalid_0's auc: 0.889394\n",
      "[84]\tvalid_0's auc: 0.889427\n",
      "[85]\tvalid_0's auc: 0.889505\n",
      "[86]\tvalid_0's auc: 0.889559\n",
      "[87]\tvalid_0's auc: 0.889641\n",
      "[88]\tvalid_0's auc: 0.889699\n",
      "[89]\tvalid_0's auc: 0.889773\n",
      "[90]\tvalid_0's auc: 0.889823\n",
      "[91]\tvalid_0's auc: 0.889885\n",
      "[92]\tvalid_0's auc: 0.88993\n",
      "[93]\tvalid_0's auc: 0.889976\n",
      "[94]\tvalid_0's auc: 0.89006\n",
      "[95]\tvalid_0's auc: 0.890104\n",
      "[96]\tvalid_0's auc: 0.89018\n",
      "[97]\tvalid_0's auc: 0.890234\n",
      "[98]\tvalid_0's auc: 0.890282\n",
      "[99]\tvalid_0's auc: 0.890324\n",
      "[100]\tvalid_0's auc: 0.890393\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.890393\n",
      "0.8903925300056434\n"
     ]
    }
   ],
   "source": [
    "params={'metric': 'auc', 'reg_alpha': 6.010538011450937, 'reg_lambda': 0.031702113663443346, 'colsample_bytree': 0.27,\n",
    "   'subsample': 0.6, 'learning_rate': 0.05, 'max_depth': 100, 'num_leaves': 100, 'min_child_samples': 216,\n",
    "   'cat_smooth': 87, 'random_state': 48,'n_estimators': 100}\n",
    "preds = np.zeros(test.shape[0])        \n",
    "kf = StratifiedKFold(n_splits=5,random_state=48,shuffle=True) #As we can see the data is unbalanced that's why I'll use StratifiedKFold to split data: Don't want all zeros in a split                 \n",
    "auc=[]   # list contains AUC for each fold  \n",
    "n=0   \n",
    "for trainVals, testVals in kf.split(train,y):\n",
    "    train_split = train.iloc[trainVals]\n",
    "    y_split = y.iloc[trainVals]\n",
    "    val_split = train.iloc[testVals]\n",
    "    y_val_split = y.iloc[testVals]\n",
    "    model = LGBMClassifier(**params) \n",
    "    model.fit(train_split,y_split, eval_set=[(val_split,y_val_split)], early_stopping_rounds=100)\n",
    "    score = roc_auc_score(y_val_split, model.predict_proba(val_split)[:, 1])\n",
    "    print(score)\n",
    "    preds += model.predict_proba(test)[:, 1]/kf.n_splits \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\"id\":testID,\"target\":preds})\n",
    "sub.to_csv(\"../output/LGB_sub2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.115566\n",
       "1         0.447129\n",
       "2         0.010611\n",
       "3         0.239745\n",
       "4         0.101847\n",
       "            ...   \n",
       "199995    0.896518\n",
       "199996    0.049339\n",
       "199997    0.701568\n",
       "199998    0.115219\n",
       "199999    0.526594\n",
       "Name: target, Length: 200000, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = pd.read_csv(\"../output/LGB_sub.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
